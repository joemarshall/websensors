{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Binary Classifier Training Example",
      "provenance": [],
      "authorship_tag": "ABX9TyOfjxPP4CcGX96MCIiqtu/B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joemarshall/websensors/blob/main/assets/python/BinaryClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This colab workbook presents a workflow for training a machine learning model for a simple classifier, then outputs it as a tflite file which can be used in the websensor platform or on a raspberry pi."
      ],
      "metadata": {
        "id": "y0x8G-ZpojrD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "UHMTFvXst49i"
      },
      "outputs": [],
      "source": [
        "# tensorflow is the machine learning library we use\n",
        "import tensorflow as tf\n",
        "# numpy is for fast python maths\n",
        "import numpy as np\n",
        "# pandas for importing datafiles\n",
        "import pandas as pd\n",
        "import io\n",
        "\n",
        "# make some stuff that is in tensorflow be \n",
        "# easier to get at below\n",
        "import tensorflow.keras as keras\n",
        "import tensorflow.keras.layers as layers\n",
        "import tensorflow.keras.losses as losses\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load datafiles - each datafile is a csv file of continuous sensor data with. \n",
        "# accompanying ground truth data ( 0 or 1)\n",
        "\n",
        "# recorded data can be from a raspberry pi or from the websensor platform\n",
        "\n",
        "# this stuff makes an upload box appear\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "9lKzFRi3uriR",
        "outputId": "6547904b-3c75-4893-e1fd-d9e3221005ad"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-da1e2b6b-f5f3-46ea-bba6-675eaee809db\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-da1e2b6b-f5f3-46ea-bba6-675eaee809db\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving speech_ground_truth.csv to speech_ground_truth (2).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocess - for each data point, add history of the previous 511 points\n",
        "# this is called 'unrolling'\n",
        "def unroll_data_and_preprocess(data,gt):\n",
        "  np_data=np.array(data)\n",
        "  np_data=(np_data/512.0) # scale the data so it isn't too big\n",
        "  return (np.lib.stride_tricks.sliding_window_view(np_data,window_shape=[512])).copy(),gt[511:]\n",
        "\n",
        "\n",
        "\n",
        "column_names=[\"sound level\",\"ground truth\"]\n",
        "\n",
        "datasets=[]\n",
        "\n",
        "for c in uploaded.keys():\n",
        "  print(f\"Loading: {c}\")\n",
        "  csv_frame=pd.read_csv(io.BytesIO(uploaded[c]))\n",
        "  file_x = csv_frame[column_names[0]].to_numpy()\n",
        "  file_y= csv_frame[column_names[1]].to_numpy()\n",
        "  datasets.append(unroll_data_and_preprocess(file_x,file_y))\n",
        "\n",
        "# make arrays for x and y\n",
        "x_data=np.concatenate([x for (x,y) in datasets])\n",
        "y_data=np.concatenate([y for (x,y) in datasets])\n",
        "print(f\"Loaded data: {x_data.shape},{y_data.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CWn7Q1f08hJ",
        "outputId": "b425d67d-9084-436d-d351-46c6d603f72b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading: speech_ground_truth.csv\n",
            "Loaded data: (6900, 512),(6900,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xz34vn2b6uw_"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# shuffle the datasets\n",
        "p = np.random.permutation(x_data.shape[0])\n",
        "x_data=x_data[p]\n",
        "y_data=y_data[p]\n",
        "\n",
        "# split the datasets into train and test\n",
        "split_point=int (x_data.shape[0]*.75 )\n",
        "#split_point=x_data.shape[0]-1\n",
        "x_train=x_data[0:split_point]\n",
        "x_test=x_data[split_point:]\n",
        "y_train=y_data[0:split_point]\n",
        "y_test=y_data[split_point:]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WF2lnOzT7rRO"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build a model - 4 convolutional layers to identify features, then a fully connected layer to output \n",
        "# the result\n",
        "model=keras.Sequential(layers=[layers.Input(name='x',shape=(512,1)),layers.Conv1D(32,kernel_size=3,padding=\"same\",strides=2,activation=\"relu\"),\n",
        "                         layers.Conv1D(32,kernel_size=3,padding=\"same\",strides=2,activation=\"relu\"),\n",
        "                         layers.Conv1D(32,kernel_size=3,padding=\"same\",strides=2,activation=\"relu\"),\n",
        "                         layers.Conv1D(32,kernel_size=3,padding=\"same\",strides=2,activation=\"relu\"),\n",
        "                         #layers.Conv1D(64,kernel_size=32,padding=\"same\",strides=32,activation=\"relu\"),\n",
        "                         layers.Flatten(),\n",
        "                         layers.Dense(64,activation=\"relu\"),\n",
        "                         layers.Dense(2,activation=\"softmax\",name='y')]) # classifier output - 0 = true, 1 = false\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',run_eagerly=False) # categorical cross-entropy loss\n",
        "model.build(input_shape=(None,512,1))\n",
        "model.summary()\n",
        "print(model.input,model.output)"
      ],
      "metadata": {
        "id": "vsYtumr07_2K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62e534d7-3bb2-4ce5-838a-f2fe1655fd0a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_8 (Conv1D)           (None, 256, 32)           128       \n",
            "                                                                 \n",
            " conv1d_9 (Conv1D)           (None, 128, 32)           3104      \n",
            "                                                                 \n",
            " conv1d_10 (Conv1D)          (None, 64, 32)            3104      \n",
            "                                                                 \n",
            " conv1d_11 (Conv1D)          (None, 32, 32)            3104      \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                65600     \n",
            "                                                                 \n",
            " y (Dense)                   (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 75,170\n",
            "Trainable params: 75,170\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 512, 1), dtype=tf.float32, name='x'), name='x', description=\"created by layer 'x'\") KerasTensor(type_spec=TensorSpec(shape=(None, 2), dtype=tf.float32, name=None), name='y/Softmax:0', description=\"created by layer 'y'\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# call train on the model\n",
        "model.fit(x_train,y_train,batch_size=32,validation_data=(x_test,y_test),epochs=50)\n"
      ],
      "metadata": {
        "id": "MIAndjiv7-CU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7ee083a9-4afc-456e-cdf9-60da5f4ecaa6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "162/162 [==============================] - 1s 6ms/step - loss: 9.3906e-06 - val_loss: 0.0039\n",
            "Epoch 2/250\n",
            "162/162 [==============================] - 1s 5ms/step - loss: 8.3997e-06 - val_loss: 0.0057\n",
            "Epoch 3/250\n",
            "162/162 [==============================] - 1s 7ms/step - loss: 8.7152e-06 - val_loss: 0.0048\n",
            "Epoch 4/250\n",
            "162/162 [==============================] - 1s 7ms/step - loss: 6.9509e-06 - val_loss: 0.0044\n",
            "Epoch 5/250\n",
            "162/162 [==============================] - 1s 7ms/step - loss: 6.4658e-06 - val_loss: 0.0044\n",
            "Epoch 6/250\n",
            "162/162 [==============================] - 1s 6ms/step - loss: 5.7906e-06 - val_loss: 0.0045\n",
            "Epoch 7/250\n",
            "162/162 [==============================] - 1s 6ms/step - loss: 5.9214e-06 - val_loss: 0.0045\n",
            "Epoch 8/250\n",
            "162/162 [==============================] - 1s 5ms/step - loss: 5.2010e-06 - val_loss: 0.0056\n",
            "Epoch 9/250\n",
            "162/162 [==============================] - 1s 6ms/step - loss: 4.5641e-06 - val_loss: 0.0043\n",
            "Epoch 10/250\n",
            "162/162 [==============================] - 1s 6ms/step - loss: 4.1289e-06 - val_loss: 0.0041\n",
            "Epoch 11/250\n",
            "162/162 [==============================] - 1s 6ms/step - loss: 3.6437e-06 - val_loss: 0.0058\n",
            "Epoch 12/250\n",
            "162/162 [==============================] - 1s 5ms/step - loss: 3.2171e-06 - val_loss: 0.0043\n",
            "Epoch 13/250\n",
            "162/162 [==============================] - 1s 6ms/step - loss: 3.4501e-06 - val_loss: 0.0046\n",
            "Epoch 14/250\n",
            "162/162 [==============================] - 1s 5ms/step - loss: 3.1647e-06 - val_loss: 0.0047\n",
            "Epoch 15/250\n",
            "162/162 [==============================] - 1s 5ms/step - loss: 2.7203e-06 - val_loss: 0.0045\n",
            "Epoch 16/250\n",
            "162/162 [==============================] - 1s 6ms/step - loss: 3.0985e-06 - val_loss: 0.0062\n",
            "Epoch 17/250\n",
            "162/162 [==============================] - 1s 7ms/step - loss: 2.2704e-06 - val_loss: 0.0066\n",
            "Epoch 18/250\n",
            "162/162 [==============================] - 1s 7ms/step - loss: 1.9489e-06 - val_loss: 0.0050\n",
            "Epoch 19/250\n",
            "162/162 [==============================] - 1s 6ms/step - loss: 1.7236e-06 - val_loss: 0.0053\n",
            "Epoch 20/250\n",
            "162/162 [==============================] - 1s 6ms/step - loss: 1.6443e-06 - val_loss: 0.0046\n",
            "Epoch 21/250\n",
            "162/162 [==============================] - 1s 6ms/step - loss: 1.7121e-06 - val_loss: 0.0057\n",
            "Epoch 22/250\n",
            "162/162 [==============================] - 1s 6ms/step - loss: 1.3919e-06 - val_loss: 0.0054\n",
            "Epoch 23/250\n",
            "162/162 [==============================] - 1s 6ms/step - loss: 1.2886e-06 - val_loss: 0.0052\n",
            "Epoch 24/250\n",
            "162/162 [==============================] - 1s 6ms/step - loss: 1.1355e-06 - val_loss: 0.0048\n",
            "Epoch 25/250\n",
            "162/162 [==============================] - 1s 6ms/step - loss: 1.0234e-06 - val_loss: 0.0068\n",
            "Epoch 26/250\n",
            "162/162 [==============================] - 1s 6ms/step - loss: 9.7138e-07 - val_loss: 0.0056\n",
            "Epoch 27/250\n",
            "162/162 [==============================] - 1s 6ms/step - loss: 8.1109e-07 - val_loss: 0.0048\n",
            "Epoch 28/250\n",
            "162/162 [==============================] - 1s 6ms/step - loss: 7.4800e-07 - val_loss: 0.0049\n",
            "Epoch 29/250\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 6.7712e-07 - val_loss: 0.0047\n",
            "Epoch 30/250\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 6.9771e-07 - val_loss: 0.0048\n",
            "Epoch 31/250\n",
            "162/162 [==============================] - 1s 5ms/step - loss: 6.5767e-07 - val_loss: 0.0055\n",
            "Epoch 32/250\n",
            "162/162 [==============================] - 1s 6ms/step - loss: 6.4983e-07 - val_loss: 0.0050\n",
            "Epoch 33/250\n",
            "162/162 [==============================] - 1s 5ms/step - loss: 5.2142e-07 - val_loss: 0.0050\n",
            "Epoch 34/250\n",
            "162/162 [==============================] - 1s 5ms/step - loss: 4.6798e-07 - val_loss: 0.0048\n",
            "Epoch 35/250\n",
            "162/162 [==============================] - 1s 5ms/step - loss: 3.7845e-07 - val_loss: 0.0047\n",
            "Epoch 36/250\n",
            "162/162 [==============================] - 1s 6ms/step - loss: 6.0326e-07 - val_loss: 0.0057\n",
            "Epoch 37/250\n",
            "162/162 [==============================] - 1s 6ms/step - loss: 8.8347e-07 - val_loss: 0.0054\n",
            "Epoch 38/250\n",
            "162/162 [==============================] - 1s 6ms/step - loss: 3.2540e-07 - val_loss: 0.0052\n",
            "Epoch 39/250\n",
            "162/162 [==============================] - 1s 6ms/step - loss: 2.8465e-07 - val_loss: 0.0045\n",
            "Epoch 40/250\n",
            "162/162 [==============================] - 1s 6ms/step - loss: 2.6387e-07 - val_loss: 0.0052\n",
            "Epoch 41/250\n",
            "162/162 [==============================] - 1s 6ms/step - loss: 2.2354e-07 - val_loss: 0.0060\n",
            "Epoch 42/250\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 2.4295e-07 - val_loss: 0.0056\n",
            "Epoch 43/250\n",
            "162/162 [==============================] - 1s 7ms/step - loss: 1.8166e-07 - val_loss: 0.0052\n",
            "Epoch 44/250\n",
            "162/162 [==============================] - 1s 5ms/step - loss: 1.9569e-07 - val_loss: 0.0056\n",
            "Epoch 45/250\n",
            "162/162 [==============================] - 1s 6ms/step - loss: 1.6606e-07 - val_loss: 0.0056\n",
            "Epoch 46/250\n",
            "162/162 [==============================] - 1s 6ms/step - loss: 1.4185e-07 - val_loss: 0.0059\n",
            "Epoch 47/250\n",
            "162/162 [==============================] - 1s 6ms/step - loss: 1.3884e-07 - val_loss: 0.0051\n",
            "Epoch 48/250\n",
            "162/162 [==============================] - 1s 6ms/step - loss: 1.2679e-07 - val_loss: 0.0049\n",
            "Epoch 49/250\n",
            "162/162 [==============================] - 1s 5ms/step - loss: 1.1580e-07 - val_loss: 0.0065\n",
            "Epoch 50/250\n",
            "162/162 [==============================] - 1s 5ms/step - loss: 1.0050e-07 - val_loss: 0.0053\n",
            "Epoch 51/250\n",
            "162/162 [==============================] - 1s 6ms/step - loss: 9.7625e-08 - val_loss: 0.0057\n",
            "Epoch 52/250\n",
            "162/162 [==============================] - 1s 6ms/step - loss: 8.8272e-08 - val_loss: 0.0057\n",
            "Epoch 53/250\n",
            "162/162 [==============================] - 1s 6ms/step - loss: 7.7515e-08 - val_loss: 0.0051\n",
            "Epoch 54/250\n",
            "162/162 [==============================] - 1s 6ms/step - loss: 7.1917e-08 - val_loss: 0.0064\n",
            "Epoch 55/250\n",
            "162/162 [==============================] - 1s 8ms/step - loss: 6.6020e-08 - val_loss: 0.0058\n",
            "Epoch 56/250\n",
            "162/162 [==============================] - 1s 7ms/step - loss: 6.0330e-08 - val_loss: 0.0054\n",
            "Epoch 57/250\n",
            "162/162 [==============================] - 1s 6ms/step - loss: 6.2173e-08 - val_loss: 0.0084\n",
            "Epoch 58/250\n",
            "162/162 [==============================] - 1s 6ms/step - loss: 5.8234e-08 - val_loss: 0.0052\n",
            "Epoch 59/250\n",
            "162/162 [==============================] - 1s 5ms/step - loss: 4.4666e-08 - val_loss: 0.0053\n",
            "Epoch 60/250\n",
            "162/162 [==============================] - 1s 6ms/step - loss: 4.0335e-08 - val_loss: 0.0057\n",
            "Epoch 61/250\n",
            "162/162 [==============================] - 1s 6ms/step - loss: 3.6627e-08 - val_loss: 0.0060\n",
            "Epoch 62/250\n",
            "162/162 [==============================] - 1s 6ms/step - loss: 3.3125e-08 - val_loss: 0.0059\n",
            "Epoch 63/250\n",
            " 79/162 [=============>................] - ETA: 0s - loss: 2.8859e-08"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-3b79c77c17a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# call train on the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1648\u001b[0m                         ):\n\u001b[1;32m   1649\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m       (concrete_function,\n\u001b[1;32m    133\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    135\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    379\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model to a tflite model for inference on raspberry pi (or websensor platform)\n",
        "converter=tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite=converter.convert()\n",
        "\n",
        "tflite_model_file = open('model.tflite',\"wb\")\n",
        "tflite_model_file.write(tflite)\n",
        "\n",
        "interpreter = tf.lite.Interpreter(model_content=tflite)\n",
        "\n",
        "signatures = interpreter.get_signature_list()\n",
        "print(signatures)\n",
        "\n",
        "from google.colab import files\n",
        "files.download('model.tflite')\n"
      ],
      "metadata": {
        "id": "gGjERc-8Rwkz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "6897a4d3-db2c-4a48-d4ce-25bfda91bb5c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'serving_default': {'inputs': ['x'], 'outputs': ['y']}}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_031d7a9e-2a62-4563-931b-712ddebb7254\", \"model.tflite\", 306904)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KqFsajgIaeqv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}